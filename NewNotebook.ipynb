{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alec-gironda/Pokemon-Variational-Autoencoder/blob/main/NewNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "w1kCd7fPJ-G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "ynW3-T5GJ9bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "7ViaJpbRKBtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_pokemon = len(os.listdir(\"drive/MyDrive/data/pokemon_jpg/pokemon_jpg/\"))\n",
        "\n",
        "ims = []\n",
        "\n",
        "for im_name in os.listdir(\"drive/MyDrive/data/pokemon_jpg/pokemon_jpg/\"):\n",
        "    s = (f\"drive/MyDrive/data/pokemon_jpg/pokemon_jpg/{str(im_name)}\")\n",
        "    curr = torchvision.io.read_image(s)\n",
        "    ims.append(curr)\n",
        "\n",
        "ims = torch.stack(ims)\n",
        "\n",
        "ims = ims/255"
      ],
      "metadata": {
        "id": "XVQI3RquKHlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder"
      ],
      "metadata": {
        "id": "jn-YC8H1KMOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.conv_layer_1 =  nn.Conv2d(3,16,5,stride = 2,padding = 2)\n",
        "        self.bn_1 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv_layer_2 =  nn.Conv2d(16,32,5,stride = 2,padding = 2)\n",
        "        self.bn_2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv_layer_3 =  nn.Conv2d(32,64,5,stride = 2,padding = 2)\n",
        "        self.bn_3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv_layer_4 =  nn.Conv2d(64,128,5,stride = 2,padding = 2)\n",
        "        self.bn_4 = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc_layer_1 = nn.Linear(32768,128)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv_layer_1(x)\n",
        "        x = self.bn_1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv_layer_2(x)\n",
        "        x = self.bn_2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv_layer_3(x)\n",
        "        x = self.bn_3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv_layer_4(x)\n",
        "        x = self.bn_4(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.fc_layer_1(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "9ExeH2zHKPH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder"
      ],
      "metadata": {
        "id": "-K79Yny9KWrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self,batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.fc_layer_1 = nn.Linear(128,32768)\n",
        "\n",
        "        self.conv_layer_1 =  nn.ConvTranspose2d(128,64,4,stride = 2,padding =1)\n",
        "        self.bn_1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.conv_layer_2 =  nn.ConvTranspose2d(64,32,4,stride = 2,padding =1)\n",
        "        self.bn_2 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.conv_layer_3 =  nn.ConvTranspose2d(32,16,4,stride = 2,padding =1)\n",
        "        self.bn_3 = nn.BatchNorm2d(16)\n",
        "\n",
        "        self.conv_layer_4 =  nn.ConvTranspose2d(16,3,4,stride = 2,padding =1)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.fc_layer_1(x)\n",
        "\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = torch.reshape(x,(self.batch_size,128,16,16))\n",
        "\n",
        "        x = self.conv_layer_1(x)\n",
        "        x = self.bn_1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv_layer_2(x)\n",
        "        x = self.bn_2(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv_layer_3(x)\n",
        "        x = self.bn_3(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv_layer_4(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = torch.reshape(x,(self.batch_size,3,256,256))\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Q5vyNCwbKYtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss"
      ],
      "metadata": {
        "id": "CZVRwD8hKbYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(input_image,output_image):\n",
        "    input_image = input_image.view(-1, 256*256)\n",
        "    output_image = output_image.view(-1, 256*256)\n",
        "    return torch.sum((input_image-output_image)**2)\n"
      ],
      "metadata": {
        "id": "VA_JpKkLKcKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set Up"
      ],
      "metadata": {
        "id": "LDEwIyhAeGiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "new_ims = ims[:800]\n",
        "\n",
        "batches = torch.reshape(new_ims,(int(len(new_ims)/batch_size),batch_size,3,256,256))\n",
        "\n",
        "encoder = Encoder().to(\"cuda\")\n",
        "decoder = Decoder(batch_size).to(\"cuda\")\n",
        "\n",
        "loss =  loss_fn # Step 2: loss\n",
        "encoder_opt = torch.optim.Adam(encoder.parameters(), lr=.01) # Step 3: training method\n",
        "decoder_opt = torch.optim.Adam(decoder.parameters(), lr=.01) # Step 3: training method"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "StDhLElyeGJY",
        "outputId": "3d0e7e7c-337b-4e72-fa40-d1bbc8855b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-678577d09fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ims\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_ims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    985\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    986\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 987\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_MODULE_LOADING'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LAZY'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "b9lsrGuYKgTh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otxXtw29e_HZ"
      },
      "outputs": [],
      "source": [
        "train_loss_history = []\n",
        "for epoch in range(500):\n",
        "  for batch in enumerate(batches):\n",
        "    train_loss = 0.0\n",
        "    encoder_opt.zero_grad()\n",
        "    decoder_opt.zero_grad()\n",
        "    encoded_out = encoder(ims[:batch_size].to(\"cuda\"))\n",
        "    decoded_out = decoder(encoded_out)\n",
        "    fit = loss(ims[:batch_size].to(\"cuda\"),decoded_out)\n",
        "    fit.backward()\n",
        "    encoder_opt.step()\n",
        "    decoder_opt.step()\n",
        "    train_loss += fit.item() / batch_size\n",
        "    train_loss_history.append(train_loss)\n",
        "    if epoch % 10 == 0:\n",
        "      print(f'Epoch {epoch}, Train loss {train_loss}')\n",
        "print(train_loss_history[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "D8exmBdkKmkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(transforms.ToPILImage()(ims[0]))\n",
        "plt.savefig(\"drive/MyDrive/original.jpg\")"
      ],
      "metadata": {
        "id": "kDsegNOTK2q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = new_ims[:batch_size].to(\"cuda\")\n",
        "out = encoder(test)\n",
        "out = decoder(out)\n",
        "out = torch.reshape(out,(batch_size,3,256,256))\n",
        "\n",
        "plt.imshow(transforms.ToPILImage()(out[0]))\n",
        "plt.savefig(\"drive/MyDrive/out.jpg\")"
      ],
      "metadata": {
        "id": "_JuYXCrwKlRH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1BtjtLV67Qf_OuY3Ie8ZUiyBlZeKRXLGR",
      "authorship_tag": "ABX9TyOl0FqDPOJaPB0/4FrQTSX2",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}